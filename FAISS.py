import numpy as np
import faiss
import json
import time

# ---------------------- Cáº¤U HÃŒNH ----------------------
EMBEDDING_FILE = 'embeddings_ver2.txt'  # hoáº·c 'embeddings_ver2.json'
TOP_K = 5  # Sá»‘ lÆ°á»£ng káº¿t quáº£ tÆ°Æ¡ng tá»± cáº§n láº¥y
SIMILARITY_THRESHOLD = 0.9  # NgÆ°á»¡ng cosine similarity Ä‘á»ƒ coi lÃ  giá»‘ng
USE_JSON = False  # True náº¿u muá»‘n Ä‘á»c tá»« JSON thay vÃ¬ TXT
# NgÆ°á»¡ng Ä‘á»ƒ chuyá»ƒn sang dÃ¹ng ANN. DÆ°á»›i má»©c nÃ y, brute-force (Flat) nhanh hÆ¡n.
ANN_THRESHOLD = 2000

# ---------------------- Äá»ŒC Dá»® LIá»†U ----------------------
print("ğŸ“‚ Äang Ä‘á»c vector embeddings ...")

try:
    if USE_JSON:
        with open(EMBEDDING_FILE, 'r', encoding='utf-8') as f:
            embeddings = np.array(json.load(f), dtype=np.float32)
    else:
        embeddings = np.loadtxt(EMBEDDING_FILE, dtype=np.float32)
except Exception as e:
    print(f"âŒ Lá»—i khi Ä‘á»c file embeddings: {e}")
    exit()

if embeddings.ndim != 2:
    print("âŒ File pháº£i lÃ  ma tráº­n 2 chiá»u (má»—i dÃ²ng 1 vector).")
    exit()

n_docs, dim = embeddings.shape
print(f"âœ… Äá»c thÃ nh cÃ´ng {n_docs} vector, má»—i vector {dim} chiá»u.\n")

# ---------------------- CHUáº¨N HÃ“A VECTOR ----------------------
print("âš™ï¸  Chuáº©n hÃ³a vector vá» Ä‘á»™ dÃ i 1 (L2 normalization)...")
faiss.normalize_L2(embeddings)

# ---------------------- XÃ‚Y Dá»°NG INDEX ----------------------
# *** Cáº¬P NHáº¬T LOGIC: Tá»± Ä‘á»™ng chá»n Index ***

if n_docs < ANN_THRESHOLD:
    # Náº¿u dá»¯ liá»‡u quÃ¡ nhá», Brute-force (Flat) nhanh hÆ¡n vÃ  chÃ­nh xÃ¡c 100%
    print(f"ğŸš€ Dá»¯ liá»‡u nhá» (< {ANN_THRESHOLD}). Sá»­ dá»¥ng IndexFlatIP (Brute-force).")
    index = faiss.IndexFlatIP(dim)
    index.add(embeddings)
    print(f"âœ… Index Ä‘Ã£ thÃªm {index.ntotal} vector.\n")
else:
    # Náº¿u dá»¯ liá»‡u Ä‘á»§ lá»›n, dÃ¹ng ANN (IVFFlat) Ä‘á»ƒ tá»‘i Æ°u
    # Heuristic: DÃ¹ng nlist = 100 cho < 1M vector, hoáº·c ~ 4*sqrt(N)
    nlist = 100
    if n_docs < 100000:
        # Äáº£m báº£o nlist * 39 < n_docs
        nlist = max(32, min(int(n_docs / 100), int(np.sqrt(n_docs))))
    else:
        nlist = max(100, int(np.sqrt(n_docs)))

    print(f"ğŸš€ Dá»¯ liá»‡u lá»›n (â‰¥ {ANN_THRESHOLD}). Sá»­ dá»¥ng IndexIVFFlat (ANN) (nlist={nlist})...")
    quantizer = faiss.IndexFlatIP(dim)
    index = faiss.IndexIVFFlat(quantizer, dim, nlist, faiss.METRIC_INNER_PRODUCT)

    print(f"ğŸ‹ï¸  Äang 'train' index trÃªn {n_docs} vector...")
    start_time = time.time()
    index.train(embeddings)
    print(f"âœ… Train hoÃ n táº¥t sau {time.time() - start_time:.2f}s.")

    print(f"â• Äang thÃªm {n_docs} vector vÃ o index...")
    start_time = time.time()
    index.add(embeddings)
    print(f"âœ… ThÃªm hoÃ n táº¥t sau {time.time() - start_time:.2f}s. (ntotal={index.ntotal})\n")

    # Äáº·t nprobe cho IndexIVF
    index.nprobe = min(20, nlist)
    print(f"   (Äáº·t nprobe = {index.nprobe})")

# ---------------------- TÃŒM KIáº¾M ----------------------
print(f"ğŸ” Äang tÃ¬m kiáº¿m (Top {TOP_K})...")

start_time = time.time()
distances, indices = index.search(embeddings, TOP_K)
end_time = time.time()
print(f"â± HoÃ n táº¥t sau {end_time - start_time:.2f}s.\n")

# ---------------------- Lá»ŒC Káº¾T QUáº¢ ----------------------
print(f"ğŸ“Š Äang lá»c káº¿t quáº£ vá»›i ngÆ°á»¡ng Similarity â‰¥ {SIMILARITY_THRESHOLD}...")
similar_pairs_set = set()  # DÃ¹ng set Ä‘á»ƒ lá»c
similar_pairs_list = []  # DÃ¹ng list Ä‘á»ƒ lÆ°u káº¿t quáº£ cuá»‘i

for i in range(n_docs):
    for rank in range(1, TOP_K):  # Bá» chÃ­nh nÃ³ (rank=0)
        j = indices[i][rank]
        if j == -1:  # KhÃ´ng tÃ¬m tháº¥y
            continue

        sim = distances[i][rank]

        # Sáº¯p xáº¿p (i, j) Ä‘á»ƒ (5, 10) vÃ  (10, 5) lÃ  nhÆ° nhau
        pair = tuple(sorted((i, j)))

        # *** Sá»¬A Lá»–I: similar_pairs_T -> similar_pairs_set ***
        if sim >= SIMILARITY_THRESHOLD and pair not in similar_pairs_set:
            similar_pairs_set.add(pair)
            similar_pairs_list.append((pair[0], pair[1], sim))

# ---------------------- HIá»‚N THá»Š Káº¾T QUáº¢ ----------------------
print(f"ğŸ¯ TÃ¬m tháº¥y {len(similar_pairs_list)} cáº·p duy nháº¥t cÃ³ Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng â‰¥ {SIMILARITY_THRESHOLD}")
if similar_pairs_list:
    # Sáº¯p xáº¿p theo Ä‘á»™ tÆ°Æ¡ng Ä‘á»“ng giáº£m dáº§n
    similar_pairs_list.sort(key=lambda x: x[2], reverse=True)

    print("\n--- 10 cáº·p tÆ°Æ¡ng tá»± nháº¥t ---")
    for (i, j, sim) in similar_pairs_list[:10]:
        print(f"Cáº·p ({i}, {j}) - Similarity = {sim:.4f}")

# ---------------------- (TÃ™Y CHá»ŒN) LÆ¯U RA FILE ----------------------
pairs_to_save = np.array([[p[0], p[1]] for p in similar_pairs_list], dtype=np.int32)
np.save('faiss_similar_pairs.npy', pairs_to_save)
print(f"\nğŸ’¾ ÄÃ£ lÆ°u {len(pairs_to_save)} cáº·p chá»‰ sá»‘ vÃ o 'faiss_similar_pairs.npy'")
print("ğŸ‰ HoÃ n táº¥t quÃ¡ trÃ¬nh tÃ¬m kiáº¿m báº±ng FAISS.")

